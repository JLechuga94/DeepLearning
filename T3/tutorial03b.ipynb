{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIAYbYajk1w9"
   },
   "source": [
    "# Tutorial 3b. Multilayer Perceptrons with Auto-differentiation!\n",
    "\n",
    "- In this tutorial you will train (again) a multilayer perceptron\n",
    "\n",
    "- But differently from what you did in `tutorial3a`, since this time, you will let the `PyTorch` library do most of the complicated work for you\n",
    "\n",
    "- The goal of this notebook is to make you get familiar with `PyTorch` and the its main concepts, that we will use repeatedly along the course.\n",
    "\n",
    "- We will be training a multilayer perceptron on the `CIFAR-10` dataset, a popular dataset of images that is used in Computer-Vision (CV) research\n",
    "\n",
    "- You will need to use a lot the documentation of `PyTorch` and look at examples for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T11:25:27.197652Z",
     "start_time": "2021-02-19T11:25:26.473286Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1545794710219,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "8yy37hEYOEiQ",
    "outputId": "4434d2e8-c5e8-4dce-8316-7f9230dc1b75"
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt \n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "- `PyTorch` provides popular computer vision datasets that can be easily downloaded\n",
    "- The following code will download the `CIFAR-10` dataset for us  \n",
    "- Since it is computationally expensive to load the entire dataset into memory, we will use `PyTorch`'s dataloaders  before feeding batches of images to the neural network\n",
    "\n",
    "**QUESTION.** Fill in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6744660d3a48b895b346986bcc3e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.CIFAR10(root = \"./data\", train = True, download = True, transform = transform)\n",
    "testset = datasets.CIFAR10(root = \"./data\", train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T12:37:41.998615Z",
     "start_time": "2021-02-19T12:37:41.993076Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2530,
     "status": "ok",
     "timestamp": 1545795192346,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "W5anlYa01w3w",
    "outputId": "dc43d91b-ad85-423f-fb18-1a0d2af22f25",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.CIFAR10(root = \"./data\", train = True, download = True, transform = transform)\n",
    "testset = datasets.CIFAR10(root = \"./data\", train = False, download = True, transform = transform)\n",
    "\n",
    "# Based on different papers using CIFAR-10 https://www.arxiv-vanity.com/papers/1804.07612/\n",
    "batch_size = 2\n",
    "\n",
    "# Verify how many cores the computer has and assign all of them to the task\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Fill in the options for both data loaders. Warning: the training dataloader should shuffle the data\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Images of CIFAR-10\n",
    "\n",
    "* Once everything is properly loaded you should be able to visualize some of the samples of the CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane plane\n"
     ]
    }
   ],
   "source": [
    "def show_images(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "show_images(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nznVMdo5edZ"
   },
   "source": [
    "## Creating a MLP model and train it\n",
    "\n",
    "- We are now ready to define all the necessary hyperparameters that are required to construct a proper MLP\n",
    "- Similarly to what we did in `tutorial03a` we need to explore the data carefully in order to know how to set the following parameters\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many rule-of-thumb methods for determining the correct number of neurons to use in the hidden layers, such as the following:\n",
    "1. The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "2. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "3. The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\n",
    "There's a geometric pyramid rule that says that whre input has m nodes and output has n nodes, the hidden layer should have  sqrt(m∗n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 9\n",
    "hidden_dim = 10\n",
    "output_dim = 10\n",
    "learning_rate = .001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graph\n",
    "\n",
    "- You are free to define any kind of architecture that you think is reasonable for the problem of classifying CIFAR-10 images\n",
    "- By default, you can use a multi-layer perceptron\n",
    "- The constructor of the neural network will represent the different components of the computation-graph, note that it is very similar to the way we have programmed our own neural network in `tutorial03a`.\n",
    "- You will also have to define the forward pass yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQawpMRPI7jm"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_dim\n",
    "        self.hidden_size  = hidden_dim\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        #self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        #self.fc1 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(self.hidden_size, output_dim)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        hidden = self.fc1(X)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(relu)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Network\n",
    "\n",
    "- You are now ready to create your neural network object\n",
    "- You will also have to define an appropriate loss function to minimize and an optimization algorithm\n",
    "- By default, you can use the cross-entropy loss and the RMS prop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPBm8qDrSWsi"
   },
   "outputs": [],
   "source": [
    "model = Net(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# CrossEntropyLoss() for a multi-class classification problem like ours\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rP0Gt5E9ajmd"
   },
   "source": [
    "### Train the Network\n",
    "\n",
    "- Once you have your neural network you just need to train it. \n",
    "- You will have to compute the output of the forward pass, compare it to your desired output and update the parameters of the network by backpropagation. \n",
    "- Fortunately this time, this only requires less than 5 lines of code in `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89814,
     "status": "ok",
     "timestamp": 1545795315447,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "SEBtAPYCFeic",
    "outputId": "edda354d-30d8-40cb-fef0-9c2a4fd968eb"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, batch_size, learning_rate):\n",
    "    iters, losses = [], []\n",
    "    iters_sub, train_acc, val_acc = [], [] ,[]\n",
    "    # training\n",
    "    \n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for xs, ts in iter(trainloader):\n",
    "            if len(ts) != batch_size:\n",
    "            continue\n",
    "        xs = xs.view(-1, 9) # flatten the image. The -1 is a wildcard\n",
    "        zs = model(xs)\n",
    "        \n",
    "        loss = criterion(zs, ts) # compute the total loss\n",
    "        loss.backward() # compute updates for each parameter\n",
    "        optimizer.step() # make the updates for each parameter\n",
    "        optimizer.zero_grad() # a clean up step for PyTorch\n",
    "        \n",
    "        # save the current training information\n",
    "        iters.append(n)\n",
    "        losses.append(float(loss)/batch_size) # compute *average* loss\n",
    "        \n",
    "        if n % 10 == 0:\n",
    "            iters_sub.append(n)\n",
    "            train_acc.append(get_accuracy(model, trainset))\n",
    "            val_acc.append(get_accuracy(model, testset))\n",
    "        # increment the iteration number\n",
    "        n += 1\n",
    "        \n",
    "    # plotting\n",
    "    plt.title(\"Training Curve (batch_size={}, lr={})\".format(batch_size, learning_rate))\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    plt.title(\"Training Curve (batch_size={}, lr={})\".format(batch_size, learning_rate))\n",
    "    plt.plot(iters_sub, train_acc, label=\"Train\")\n",
    "    plt.plot(iters_sub, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Of course, repeated calls to `train` will continue training from where it were\n",
    "- Training a neural network is a highly iterative process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpAJUiHm529m"
   },
   "source": [
    "## Evaluate the final performance of the Network\n",
    "\n",
    "- Once you think your network is properly trained, you will test its performance on the testing-set of the CIFAR-10 dataset\n",
    "- Compute the final accuracy of your model\n",
    "- You should be able to reach a 50% accuracy with a simple multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2278,
     "status": "ok",
     "timestamp": 1545795466013,
     "user": {
      "displayName": "Buomsoo Kim",
      "photoUrl": "",
      "userId": "18268696804115368229"
     },
     "user_tz": 420
    },
    "id": "txXH3dknFpSx",
    "outputId": "9330f014-2687-4464-b495-1ba861511e38"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final remark.** Of course, this is far from being the state-of-the-art. Indeed, convolutional neural nets are the backbones for computer vision problems (we will do it in following labs), while we only used here a feed-forward network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T11:20:48.131197Z",
     "start_time": "2021-02-19T11:20:48.126926Z"
    }
   },
   "source": [
    "## Redo it using `pytorch-lightning`\n",
    "\n",
    "There is some boilerplates in pure `PyTorch` code. The `pytorch-lighting` library is a new library allowing to simplify a lot the use of `PyTorch` together with very nice options for faster training and development.\n",
    "\n",
    "**QUESTION**. Recode your neural network and its training using `pytorch-lightning`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL-with-pytorch - 2 [MLP].ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
