{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1. Polynomial logistic regression versus multi-layer perceptron\n",
    "\n",
    "In this notebook, we compare on toy datasets the polynomial logistic regression with a multi-layer perceptron (MLP) for binary classification.\n",
    "\n",
    "- Polynomial logistic regression is a basic example of a linear method (logistic regression) applied on hand-made features (involving feature engineering)\n",
    "- Multi-layer perceptron won't benefit from the hand-made polynomial features\n",
    "\n",
    "This example is therefore a toy comparison, on toy datasets, of a hand-craft approach, with hand-made polynomial features and a purely data-driven approach, based on a MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of three datasets for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.545864Z",
     "start_time": "2021-02-01T16:38:02.474659Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_moons, make_classification, make_circles\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "def make_linear(n_samples):    \n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples, n_features=2, n_redundant=0, n_informative=2, \n",
    "        random_state=1, n_clusters_per_class=1\n",
    "     )\n",
    "    rng = np.random.RandomState(2)\n",
    "    X += 2 * rng.uniform(size=X.shape)\n",
    "    return X, y\n",
    "\n",
    "n_samples = 150\n",
    "\n",
    "datasets = [\n",
    "    (make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1), \"circles\"),\n",
    "    (make_moons(n_samples=n_samples, noise=0.2, random_state=0), \"moons\"),\n",
    "    (make_linear(n_samples=n_samples), \"linear\")\n",
    "]\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "def plot_data(ax, X, y, xy_labels=True, **kwargs):\n",
    "    X_1 = X[y == 1]\n",
    "    X_0 = X[y == 0]\n",
    "    plt.scatter(X_1[:, 0], X_1[:, 1], c=\"blue\", s=30, label=r\"$y_i=1$\", **kwargs)\n",
    "    plt.scatter(X_0[:, 0], X_0[:, 1], c=\"red\", s=30, label=r\"$y_i=-1$\", **kwargs)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    if xy_labels:\n",
    "        ax.set_xlabel(r\"$x_{i,1}$\", fontsize=15)\n",
    "        ax.set_ylabel(r\"$x_{i,2}$\", fontsize=15)\n",
    "    ax.set_xlim(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5)\n",
    "    ax.set_ylim(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5)\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "for i, ((X, y), name) in enumerate(datasets):\n",
    "    ax = plt.subplot(1, n_datasets, i + 1)\n",
    "    plot_data(ax, X, y, alpha=0.5)\n",
    "    plt.title(name, fontsize=18)\n",
    "\n",
    "plt.legend(fontsize=14, loc=\"center right\", bbox_to_anchor=(1.7, 0.5))\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"tutorial01b_toy_samples.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision functions of the logistic regression on these datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.556138Z",
     "start_time": "2021-02-01T16:38:04.547808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit the model on data\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.561292Z",
     "start_time": "2021-02-01T16:38:04.558311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Learned weights\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.566157Z",
     "start_time": "2021-02-01T16:38:04.563237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Learned intercept\n",
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.570734Z",
     "start_time": "2021-02-01T16:38:04.567657Z"
    }
   },
   "outputs": [],
   "source": [
    "# To predict the label\n",
    "clf.predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.575396Z",
     "start_time": "2021-02-01T16:38:04.572144Z"
    }
   },
   "outputs": [],
   "source": [
    "# To get predictions of the probability\n",
    "clf.predict_proba(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:04.580616Z",
     "start_time": "2021-02-01T16:38:04.577008Z"
    }
   },
   "outputs": [],
   "source": [
    "# The decision function: it's x w + b (the linear transform before applying the sigmoid)\n",
    "clf.decision_function(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display of the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:07.809970Z",
     "start_time": "2021-02-01T16:38:07.185471Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "plt.figure(figsize=(12, 3))\n",
    "h = 0.02\n",
    "levels = 20\n",
    "\n",
    "def plot_hyperplane(clf, x_min=-10., x_max=10.):\n",
    "    if isinstance(clf, Pipeline):\n",
    "        w1, w2 = clf[\"logreg\"].coef_[0]\n",
    "        b = clf[\"logreg\"].intercept_\n",
    "    else:\n",
    "        w1, w2 = clf.coef_[0]\n",
    "        b = clf.intercept_\n",
    "\n",
    "    x = np.linspace(-10, 10, 1000)\n",
    "    y = -(b + w1 * x) / w2\n",
    "    plt.plot(x, y, lw=2, ls=\"--\", color=\"black\", alpha=0.6, \n",
    "             label=r\"$w \\cdot x + b = 0$\")\n",
    "\n",
    "def plot_data(ax, X, y, xy_labels=True, **kwargs):\n",
    "    X_1 = X[y == 1]\n",
    "    X_0 = X[y == 0]\n",
    "    plt.scatter(X_1[:, 0], X_1[:, 1], c=\"blue\", s=30, label=r\"$y_i=1$\", **kwargs)\n",
    "    plt.scatter(X_0[:, 0], X_0[:, 1], c=\"red\", s=30, label=r\"$y_i=-1$\", **kwargs)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    if xy_labels:\n",
    "        ax.set_xlabel(r\"$x_{i,1}$\", fontsize=15)\n",
    "        ax.set_ylabel(r\"$x_{i,2}$\", fontsize=15)\n",
    "    ax.set_xlim(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5)\n",
    "    ax.set_ylim(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5)\n",
    "\n",
    "\n",
    "def plot_probas(clf, ax, X, y, h=0.02, levels=20, colorbar=True):\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))    \n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ct = ax.contourf(xx, yy, Z, cmap=cm, alpha=.7, levels=levels)\n",
    "    if colorbar:\n",
    "        cbar = plt.colorbar(ct)\n",
    "        cbar.ax.set_xlabel(r\"$\\sigma(x \\cdot w + b)$\")\n",
    "    \n",
    "for i, ((X, y), name) in enumerate(datasets):\n",
    "    ax = plt.subplot(1, n_datasets, i + 1)\n",
    "    clf.fit(X, y)\n",
    "    plot_probas(clf, ax, X, y, h=h, levels=levels)\n",
    "    plot_hyperplane(clf, x_min=X[:, 0].min(), x_max=X[:, 0].max())\n",
    "    plot_data(ax, X, y, xy_labels=False, alpha=0.5)\n",
    "    plt.title(name, fontsize=18)\n",
    "\n",
    "lgd = plt.legend(fontsize=14, loc=\"lower center\", ncol=3, bbox_to_anchor=(-0.9, -0.35))\n",
    "\n",
    "# plt.savefig(\"tutorial01b_logistic_probas.pdf\", \n",
    "#             bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision function of a polynomial logistic regression\n",
    "\n",
    "Let's use the `PolynomialFeatures` transformer before performing the logistic regression in a scikit-learn `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:18.694179Z",
     "start_time": "2021-02-01T16:38:18.179658Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"logreg\", LogisticRegression())\n",
    "])\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "plt.figure(figsize=(12, 3))\n",
    "h = 0.02\n",
    "levels = 20\n",
    "\n",
    "for i, ((X, y), name) in enumerate(datasets):\n",
    "    print(name)\n",
    "    ax = plt.subplot(1, n_datasets, i + 1)\n",
    "    clf.fit(X, y)\n",
    "    print(clf[\"logreg\"].coef_)\n",
    "    plot_probas(clf, ax, X, y, h=h, levels=levels)\n",
    "    plot_data(ax, X, y, xy_labels=False, alpha=0.5)\n",
    "    plt.title(name, fontsize=18)\n",
    "\n",
    "lgd = plt.legend(fontsize=14, loc=\"lower center\", ncol=3, bbox_to_anchor=(-0.9, -0.35))\n",
    "\n",
    "# plt.savefig(\"tutorial01b_poly_logistic_decision.pdf\", \n",
    "#             bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the classifiers  using a classification report\n",
    "\n",
    "Using the following classifiers: **simple logistic regression** and **polynomial logistic regression**, and let's scale the features before hand in the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:23.248154Z",
     "start_time": "2021-02-01T16:38:23.244442Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf_simple = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression())\n",
    "])\n",
    "\n",
    "clf_poly = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"logreg\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split the data into a **training** and a **testing** set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:24.386834Z",
     "start_time": "2021-02-01T16:38:24.380130Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's use the \"circles\" dataset with more samples\n",
    "n_samples = 1000\n",
    "\n",
    "X, y = make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1)\n",
    "\n",
    "# And split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:26.857829Z",
     "start_time": "2021-02-01T16:38:26.828946Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (classification_report, roc_curve, \n",
    "                             precision_recall_curve, roc_auc_score, \n",
    "                             average_precision_score)\n",
    "\n",
    "clf_simple.fit(X_train, y_train)\n",
    "clf_poly.fit(X_train, y_train)\n",
    "\n",
    "msg = \"Classification report for clf_simple\"\n",
    "print(msg)\n",
    "print(\"-\" * len(msg))\n",
    "report_simple = classification_report(y_test, clf_simple.predict(X_test))\n",
    "print(report_simple)\n",
    "\n",
    "msg = \"Classification report for clf_poly\"\n",
    "print(msg)\n",
    "print(\"-\" * len(msg))\n",
    "report_poly = classification_report(y_test, clf_poly.predict(X_test))\n",
    "print(report_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** `macro avg` is the average of the metrics while `weighted avg` is the average weighted by the label proportions (important when data is unbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the classifiers  using a ROC and PR curves\n",
    "\n",
    "Let us first get the scores for the label 1 of the simple and the polynomial logistic regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:28.788687Z",
     "start_time": "2021-02-01T16:38:28.785052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the scores for class 1 of the simple and polynomial logistic regressions\n",
    "y_score_simple = clf_simple.predict_proba(X_test)[:, 1]\n",
    "y_score_poly = clf_poly.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell are **custom function** to plot nice-looking ROC curves with or without the thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:29.874473Z",
     "start_time": "2021-02-01T16:38:29.815823Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_score, title=None, label=None, legend=True, \n",
    "                   show_thresholds=True, colorbar=True):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    thresholds[0] = 1\n",
    "    roc_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "    if label is None:\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc\n",
    "\n",
    "    if title is None:\n",
    "        title = \"ROC curve\"\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "    \n",
    "    if show_thresholds:\n",
    "        norm = plt.Normalize(vmin=0, vmax=1)\n",
    "        plt.plot(fpr, tpr, lw=1, label=label, alpha=0.7)\n",
    "        plt.scatter(fpr, tpr, cmap=cm, c=thresholds, s=70, norm=norm)\n",
    "        if colorbar:\n",
    "            plt.colorbar()\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, lw=3, label=label)\n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    if legend:\n",
    "        plt.legend(fontsize=12)\n",
    "\n",
    "def plot_roc_curves(y_test, y_scores, labels, title=None, show_thresholds=True):\n",
    "    for y_score, label in zip(y_scores, labels):\n",
    "        plot_roc_curve(y_test, y_score, label=label, legend=False, \n",
    "                       show_thresholds=show_thresholds, colorbar=False)\n",
    "    plt.legend(fontsize=12)\n",
    "    if show_thresholds:\n",
    "        plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=16)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:31.871932Z",
     "start_time": "2021-02-01T16:38:31.686442Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5))\n",
    "plot_roc_curve(y_test, y_score_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:32.093488Z",
     "start_time": "2021-02-01T16:38:31.875364Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5))\n",
    "plot_roc_curves(y_test, [y_score_simple, y_score_poly], \n",
    "                labels=[\"Simple LR\", \"Poly LR\"],\n",
    "                title=\"ROC curve of Simple VS Poly LR \")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"tutorial01b_roc_curves_with_thresholds.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the exact same thing with the precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:33.330585Z",
     "start_time": "2021-02-01T16:38:33.323735Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pr_curve(y_test, y_score, title=None, label=None, legend=True, \n",
    "                   show_thresholds=True, colorbar=True):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    precision = precision[:-1]\n",
    "    recall = recall[:-1]\n",
    "    avg_prec = average_precision_score(y_test, y_score)\n",
    "\n",
    "    if label is None:\n",
    "        label='PR curve (area = %0.2f)' % avg_prec\n",
    "\n",
    "    if title is None:\n",
    "        title = \"PR curve\"\n",
    "    \n",
    "    if show_thresholds:\n",
    "        norm = plt.Normalize(vmin=0, vmax=1)\n",
    "        plt.plot(recall, precision, lw=1, label=label, alpha=0.7)\n",
    "        plt.scatter(recall, precision, cmap=cm, c=thresholds, s=70, norm=norm)\n",
    "        if colorbar:\n",
    "            plt.colorbar()\n",
    "    else:\n",
    "        plt.plot(recall, precision, lw=3, label=label)\n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=14)\n",
    "    plt.ylabel('Precision', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    if legend:\n",
    "        plt.legend(fontsize=12)\n",
    "\n",
    "def plot_pr_curves(y_test, y_scores, labels, title=None, show_thresholds=True):\n",
    "    for y_score, label in zip(y_scores, labels):\n",
    "        plot_pr_curve(y_test, y_score, label=label, legend=False, \n",
    "                       show_thresholds=show_thresholds, colorbar=False)\n",
    "    plt.legend(fontsize=12)\n",
    "    if show_thresholds:\n",
    "        plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=16)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:33.890300Z",
     "start_time": "2021-02-01T16:38:33.673129Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5))\n",
    "plot_pr_curves(y_test, [y_score_simple, y_score_poly], \n",
    "               labels=[\"Simple LR\", \"Poly LR\"],\n",
    "               title=\"ROC curve of Simple VS Poly LR \")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"tutorial01b_pr_curves_with_thresholds.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons over the three datasets using all the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:35.236203Z",
     "start_time": "2021-02-01T16:38:35.177270Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "datasets = [\n",
    "    (make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1), \"circles\"),\n",
    "    (make_moons(n_samples=n_samples, noise=0.2, random_state=0), \"moons\"),\n",
    "    (make_linear(n_samples=n_samples), \"linear\")\n",
    "]\n",
    "\n",
    "clf_simple = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression())\n",
    "])\n",
    "\n",
    "clf_poly = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"logreg\", LogisticRegression())\n",
    "])    \n",
    "\n",
    "classifiers = [\n",
    "    (clf_simple, \"Simple LR\"),\n",
    "    (clf_poly, \"Poly LR\")\n",
    "]\n",
    "\n",
    "dataset_names = []\n",
    "classifier_names = []\n",
    "auc_prs = []\n",
    "auc_rocs = []\n",
    "\n",
    "for (X, y), dataset_name in datasets:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    for clf, classifier_name in classifiers:\n",
    "        # Train\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Predict scores\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "        # Compute AUC-ROC and AUC-PR (average-precision)\n",
    "        auc_roc = roc_auc_score(y_test, y_score)\n",
    "        auc_pr = average_precision_score(y_test, y_score)\n",
    "        # Append computations in the lists\n",
    "        dataset_names.append(dataset_name)\n",
    "        classifier_names.append(classifier_name)\n",
    "        auc_prs.append(auc_pr)\n",
    "        auc_rocs.append(auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:36.787912Z",
     "start_time": "2021-02-01T16:38:36.777966Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"dataset\": dataset_names,\n",
    "    \"classifier\": classifier_names,\n",
    "    \"AUC-ROC\": auc_rocs,\n",
    "    \"AUC-PR\": auc_prs\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to display the methods against the datasets, so let's **pivot** the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:38:37.962625Z",
     "start_time": "2021-02-01T16:38:37.896648Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    results\n",
    "    .pivot(index=\"classifier\", columns=\"dataset\")\n",
    "    .style\n",
    "    .background_gradient()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that on the **circles** dataset, **Poly LR** is much better than **Simple LR**, while on the **linear** and the **moons** datasets, Simple LR and Poly LR have similar performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of overfitting with polynomial logistic regression\n",
    "\n",
    "Let's illustrate overfitting by increasing the degree of the polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:39:49.075892Z",
     "start_time": "2021-02-01T16:39:49.072584Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_poly_logreg(degree):\n",
    "    clf = Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"scale\", StandardScaler()),        \n",
    "        (\"logreg\", LogisticRegression(penalty=\"none\", max_iter=5000))\n",
    "    ])\n",
    "    clf_name = \"LR with degree={:02d}\".format(degree)\n",
    "    return clf, clf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:39:23.770553Z",
     "start_time": "2021-02-01T16:39:20.768334Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 150\n",
    "\n",
    "datasets = [\n",
    "    (make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1), \"circles\"),\n",
    "    (make_moons(n_samples=n_samples, noise=0.2, random_state=0), \"moons\"),\n",
    "    (make_linear(n_samples=n_samples), \"linear\")\n",
    "]\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5, 15]\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "n_clfs = len(degrees) \n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(3 * n_datasets, 3 * n_clfs))\n",
    "\n",
    "for n_clf, degree in enumerate(degrees):\n",
    "    for n_dataset, ((X, y), dataset_name) in enumerate(datasets):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "        clf, clf_name = get_poly_logreg(degree)\n",
    "        clf.fit(X_train, y_train)\n",
    "        i += 1\n",
    "        ax = plt.subplot(n_clfs, n_datasets, i)\n",
    "        plot_probas(clf, ax, X_train, y_train, h=h, levels=levels, colorbar=False)\n",
    "        plot_data(ax, X_train, y_train, xy_labels=False, alpha=0.5)\n",
    "        \n",
    "        if n_clf == 0:\n",
    "            plt.title(dataset_name, fontsize=18)\n",
    "        \n",
    "        if n_dataset % 3 == 0:\n",
    "            plt.ylabel(clf_name, fontsize=18)\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative assessment of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:40:13.523338Z",
     "start_time": "2021-02-01T16:39:56.078853Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_names = []\n",
    "clfs_names = []\n",
    "train_auc_prs = []\n",
    "train_auc_rocs = []\n",
    "test_auc_prs = []\n",
    "test_auc_rocs = []\n",
    "clf_degrees = []\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "datasets = [\n",
    "    (make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1), \"circles\"),\n",
    "    (make_moons(n_samples=n_samples, noise=0.2, random_state=0), \"moons\"),\n",
    "    (make_linear(n_samples=n_samples), \"linear\")\n",
    "]\n",
    "\n",
    "degrees = [1, 2, 3, 4, 5, 10, 15, 20, 30]\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "n_clfs = len(degrees) \n",
    "i = 0\n",
    "\n",
    "for n_clf, degree in enumerate(degrees):\n",
    "    for n_dataset, ((X, y), dataset_name) in enumerate(datasets):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "        clf, clf_name = get_poly_logreg(degree)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Compute metrics\n",
    "        clf_degrees.append(degree)\n",
    "        clfs_names.append(clf_name)\n",
    "        dataset_names.append(dataset_name)\n",
    "        \n",
    "        y_train_score = clf.predict_proba(X_train)[:, 1]\n",
    "        y_test_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        train_auc_roc = roc_auc_score(y_train, y_train_score)\n",
    "        test_auc_roc = roc_auc_score(y_test, y_test_score)\n",
    "        train_auc_pr = average_precision_score(y_train, y_train_score)\n",
    "        test_auc_pr = average_precision_score(y_test, y_test_score)\n",
    "\n",
    "        train_auc_rocs.append(train_auc_roc)\n",
    "        test_auc_rocs.append(test_auc_roc)\n",
    "        train_auc_prs.append(train_auc_pr)        \n",
    "        test_auc_prs.append(test_auc_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:40:13.530151Z",
     "start_time": "2021-02-01T16:40:13.525864Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"dataset\": dataset_names,\n",
    "    \"degree\": clf_degrees,\n",
    "    \"AUC-PR (train)\": train_auc_prs,\n",
    "    \"AUC-PR (test)\": test_auc_prs,\n",
    "    \"AUC-ROC (train)\": train_auc_rocs,\n",
    "    \"AUC-ROC (test)\": test_auc_rocs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:40:13.545382Z",
     "start_time": "2021-02-01T16:40:13.532980Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:40:13.612131Z",
     "start_time": "2021-02-01T16:40:13.547881Z"
    }
   },
   "outputs": [],
   "source": [
    "results_pivot = (\n",
    "    results\n",
    "    .pivot(index=\"degree\", columns=\"dataset\")\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    results_pivot\n",
    "    .style\n",
    "    .background_gradient()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:40:13.897196Z",
     "start_time": "2021-02-01T16:40:13.614321Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"degree\", \n",
    "    y=\"AUC-PR (train)\",\n",
    "    hue=\"dataset\",\n",
    "    linewidth=2,\n",
    "    data=results.iloc[3:, :], \n",
    "    marker=\".\", \n",
    "    markersize=20\n",
    ").set_title(\"AUC-PR (train)\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:40:14.081710Z",
     "start_time": "2021-02-01T16:40:13.899121Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    x=\"degree\", \n",
    "    y=\"AUC-PR (test)\",\n",
    "    hue=\"dataset\",\n",
    "    linewidth=2,\n",
    "    data=results.iloc[3:, :], \n",
    "    marker=\".\", \n",
    "    markersize=20\n",
    ").set_title(\"AUC-PR (test)\", fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial logistic regression versus MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:41:03.801257Z",
     "start_time": "2021-02-01T16:41:03.789901Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "n_samples = 150\n",
    "\n",
    "datasets = [\n",
    "    (make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1), \"circles\"),\n",
    "    (make_moons(n_samples=n_samples, noise=0.2, random_state=0), \"moons\"),\n",
    "    (make_linear(n_samples=n_samples), \"linear\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:41:09.491304Z",
     "start_time": "2021-02-01T16:41:04.020841Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_poly_logreg(degree):\n",
    "    clf = Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"scale\", StandardScaler()),        \n",
    "        (\"logreg\", LogisticRegression())\n",
    "    ])\n",
    "    clf_name = \"LR with degree={:02d}\".format(degree)\n",
    "    return clf, clf_name\n",
    "\n",
    "# Polynomial logistic regression with degree 2 and 3\n",
    "poly_logreg_2 = get_poly_logreg(degree=2)\n",
    "poly_logreg_3 = get_poly_logreg(degree=3)\n",
    "\n",
    "\n",
    "# Multi-layer perceptron classifier with 2 hidden layers of width 16\n",
    "mlp = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(solver=\"adam\", hidden_layer_sizes=(16,), batch_size=16,\n",
    "                          max_iter=2000))\n",
    "])\n",
    "\n",
    "clfs = [\n",
    "    poly_logreg_2,\n",
    "    poly_logreg_3,\n",
    "    (mlp, \"MLP (16,)\")\n",
    "]\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "n_clfs = len(clfs) \n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(3 * n_datasets, 3 * n_clfs))\n",
    "\n",
    "for n_clf, (clf, clf_name) in enumerate(clfs):\n",
    "    for n_dataset, ((X, y), dataset_name) in enumerate(datasets):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        i += 1\n",
    "        # print((n_clfs, n_datasets, i), n_clf, n_dataset)\n",
    "        ax = plt.subplot(n_clfs, n_datasets, i)\n",
    "        plot_probas(clf, ax, X_train, y_train, h=h, levels=levels, colorbar=False)\n",
    "        plot_data(ax, X_train, y_train, xy_labels=False, alpha=0.5)\n",
    "        \n",
    "        if n_clf == 0:\n",
    "            plt.title(dataset_name, fontsize=18)\n",
    "        \n",
    "        if n_dataset % 3 == 0:\n",
    "            plt.ylabel(clf_name, fontsize=18)\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning\n",
    "\n",
    "Something is seriously wrong in what we did before: we did not performed hyper-parameter optimization using cross-validation. \n",
    "Let's do it to tune both the degree of the polynomial and regularization level of the polynomial logistic regression, and for the hyper-parameters of the MLP.\n",
    "But let's do it only on the moons dataset, since it takes some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:41:09.499387Z",
     "start_time": "2021-02-01T16:41:09.493661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "X, y = make_moons(n_samples=n_samples, noise=0.2, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# A stratified K-Fold cross-validator\n",
    "cv = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:29:58.620224Z",
     "start_time": "2021-01-29T12:29:56.804031Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_logreg = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"logreg\", LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "poly_logreg_params = {\n",
    "    \"logreg__C\": [1e-3, 1e-2, 1e-1, 1.0, 1e1, 1e2, 1e3],\n",
    "    \"poly__degree\": [1, 2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "poly_logreg_cv = GridSearchCV(poly_logreg, poly_logreg_params, n_jobs=-1, scoring=\"roc_auc\", cv=cv)\n",
    "poly_logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:30:00.030274Z",
     "start_time": "2021-01-29T12:30:00.026374Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:32:41.182671Z",
     "start_time": "2021-01-29T12:30:01.252482Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "mlp = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"mlp\", MLPClassifier(solver=\"adam\", \n",
    "                          hidden_layer_sizes=(16,), \n",
    "                          batch_size=16,\n",
    "                          max_iter=2000)\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "mlp_params = {\n",
    "    \"mlp__batch_size\": [8, 16, 32, 64, 128],\n",
    "    \"mlp__alpha\": [1e-1, 1e-2, 1e-3, 1e-4],\n",
    "    \"mlp__activation\": [\"relu\", \"tanh\"],\n",
    "    \"mlp__hidden_layer_sizes\": [(16,), (32,), (16, 16,), (8, 8)]\n",
    "}\n",
    "\n",
    "mlp_cv = GridSearchCV(mlp, mlp_params, n_jobs=-1, scoring=\"roc_auc\", cv=cv)\n",
    "mlp_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:42:07.425346Z",
     "start_time": "2021-01-29T12:42:07.421382Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:42:10.626087Z",
     "start_time": "2021-01-29T12:42:10.623050Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_score(clf, X_test, y_test):\n",
    "    y_test_score = clf.predict_proba(X_test)[:, 1]\n",
    "    test_auc_roc = roc_auc_score(y_test, y_test_score)\n",
    "    return test_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:42:14.093965Z",
     "start_time": "2021-01-29T12:42:14.087339Z"
    }
   },
   "outputs": [],
   "source": [
    "get_test_score(poly_logreg_cv, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T12:42:14.216621Z",
     "start_time": "2021-01-29T12:42:14.210820Z"
    }
   },
   "outputs": [],
   "source": [
    "get_test_score(mlp_cv, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
